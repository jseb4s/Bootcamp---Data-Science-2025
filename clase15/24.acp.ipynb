{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d04199a3",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "En Machine Learning, muchas veces trabajamos con bases de datos que tienen muchas variables. Esto se conoce como alta dimensionalidad. Pero tener muchas variables puede traer problemas:\n",
    "\n",
    "- El modelo puede aprender demasiado los datos de entrenamiento (sobreajuste).\n",
    "\n",
    "- El cálculo se vuelve más lento y costoso.\n",
    "\n",
    "- Algunas variables pueden estar diciendo lo mismo (redundancia).\n",
    "\n",
    "Solución: Usamos técnicas de \"reducción de dimensionalidad\" para simplificar los datos sin perder demasiada información."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3069088",
   "metadata": {},
   "source": [
    "# Teoría de Reducción de Dimensionalidad\n",
    "\n",
    "## ¿Qué es la reducción de dimensionalidad?\n",
    "\n",
    "Es un proceso para reducir el número de variables (tambien llamadas \"características\") en un conjunto de datos, manteniendo la mayor cantidad posible de información importante.\n",
    "\n",
    "Imagina que tienes una tabla con 20 columnas (variables). El objetivo de estas técnicas es transformarlas en 2, 3 o 5 nuevas columnas que sean representaciones de las anteriores, pero que capturen lo más importante.\n",
    "\n",
    "### Tipos de técnicas\n",
    "\n",
    "- Análisis de Componentes Principales (ACP o PCA): Para variables cuantitativas (números).\n",
    "\n",
    "- Análisis de Correspondencias Múltiples (ACM o MCA): Para variables cualitativas (categóricas).\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98c4da9",
   "metadata": {},
   "source": [
    "# Análisis de Componentes Principales (ACP o PCA)\n",
    "\n",
    "### Objetivo del ACP\n",
    "\n",
    "Reducir el número de variables cuantitativas originales generando nuevas variables llamadas \"componentes principales\". Estas componentes son:\n",
    "\n",
    "- Combinaciones lineales de las variables originales.\n",
    "\n",
    "- No correlacionadas entre sí (ortogonales).\n",
    "\n",
    "- Ordenadas según la cantidad de varianza que explican."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f25a161",
   "metadata": {},
   "source": [
    "## Paso 1: Normalización de datos (estandarización) de los datos\n",
    "\n",
    "Supongamos que tienes 3 variables: Ingreso, Edad y Gasto. Si no estandarizamos:\n",
    "\n",
    "- Ingreso puede estar entre 0 y 10.000\n",
    "\n",
    "- Edad entre 0 y 100\n",
    "\n",
    "- Gasto entre 0 y 3.000\n",
    "\n",
    "Como los rangos son distintos, la variable con más escala dominará el ACP.\n",
    "\n",
    "\n",
    "### Ecuación para estandarizar:\n",
    "\n",
    "$$\n",
    "Z_{ij} = \\frac{X_{ij} - \\bar{X}_j}{s_j}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- $X_{ij}$: valor original del individuo $i$ en la variable $j$.\n",
    "- $\\bar{X}_j$: promedio de la variable $j$.\n",
    "- $s_j$: desviación estándar de la variable $j$.\n",
    "- $Z_{ij}$: valor estandarizado. Tendrá media 0 y desviación estándar 1.\n",
    "\n",
    "\n",
    "Normalización: \n",
    "[Google](https://developers.google.com/machine-learning/crash-course/numerical-data/normalization?hl=es-419)\n",
    "[Microsoft](https://learn.microsoft.com/es-es/azure/machine-learning/component-reference/normalize-data?view=azureml-api-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3a26af",
   "metadata": {},
   "source": [
    "## Paso 2: Calcular matriz de covarianzas o de correlaciones\n",
    "\n",
    "Una vez estandarizados los datos, se calcula una matriz que muestra cuánta relación hay entre cada par de variables.\n",
    "\n",
    "Ecuación\n",
    "\n",
    "$$\n",
    "\\mathbf{S} = \\frac{1}{n - 1} \\mathbf{Z}^T \\mathbf{Z}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- $\\mathbf{Z}$: matriz de datos estandarizados (filas = individuos, columnas = variables).\n",
    "- $\\mathbf{S}$: matriz de covarianza si usamos los valores reales, o matriz de correlación si están estandarizados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a92693f",
   "metadata": {},
   "source": [
    "## Paso 3: Calcular autovalores y autovectores\n",
    "\n",
    "- **Autovalores** ($\\lambda$): indican cuánta varianza explica cada componente.\n",
    "- **Autovectores** ($\\mathbf{v}$): indican cómo combinar las variables originales para formar los nuevos componentes.\n",
    "\n",
    "Se resuelve:\n",
    "\n",
    "$$\n",
    "\\mathbf{S} \\mathbf{v} = \\lambda \\mathbf{v}\n",
    "$$\n",
    "\n",
    "Esto da lugar a tantos componentes como variables originales, pero normalmente solo usamos los que explican la mayor parte de la varianza.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc0aa12",
   "metadata": {},
   "source": [
    "## Paso 4: Calcular los componentes principales\n",
    "\n",
    "Cada componente es una combinación lineal:\n",
    "\n",
    "$$\n",
    "\\text{CP}_k = z_1 v_{1k} + z_2 v_{2k} + \\dots + z_p v_{pk}\n",
    "$$\n",
    "\n",
    "Es decir, multiplicamos cada variable estandarizada $z_j$ por su coeficiente en el autovector $v_{jk}$.\n",
    "\n",
    "Se obtienen nuevas variables: CP1, CP2, ..., CP$_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9bc274",
   "metadata": {},
   "source": [
    "## Paso 5: Evaluar la calidad del ACP\n",
    "\n",
    "1. **Varianza explicada**\n",
    "\n",
    "$$\n",
    "\\text{Varianza explicada} = \\frac{\\lambda_k}{\\sum_{j=1}^p \\lambda_j}\n",
    "$$\n",
    "\n",
    "Se interpreta como: \"El porcentaje de la información total que representa ese componente\".\n",
    "\n",
    "2. **Varianza acumulada**  \n",
    "Suma de las varianzas explicadas por los primeros componentes.  \n",
    "Por ejemplo, si CP1 y CP2 explican juntos el 85% de la varianza, entonces podemos usar solo ellos.\n",
    "\n",
    "3. **Scree plot**  \n",
    "Gráfico de los autovalores ordenados. Buscamos el \"codo\" (el punto donde la varianza deja de ser importante).\n",
    "\n",
    "4. **Contribuciones**  \n",
    "- **De variables**: Cuánto aporta cada variable a cada componente.  \n",
    "- **De individuos**: Cuánto representa un individuo dentro del componente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46fe359",
   "metadata": {},
   "source": [
    "# Análisis de Correspondencias Múltiples (ACM / MCA)\n",
    "\n",
    "¿Cuándo usar ACM?\n",
    "\n",
    "Cuando nuestras variables son categóricas (no numéricas). Ejemplo:\n",
    "\n",
    "- Sexo: Hombre / Mujer\n",
    "\n",
    "- Ciudad: Bogotá / Medellín / Cali\n",
    "\n",
    "- Producto: A / B / C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fe1d45",
   "metadata": {},
   "source": [
    "## Paso 1: Convertir a variables dummies\n",
    "\n",
    "Creamos una columna por cada categoría posible. Por ejemplo:\n",
    "\n",
    "- Sexo:\n",
    "\n",
    "        Hombre → [1, 0]\n",
    "\n",
    "        Mujer → [0, 1]\n",
    "\n",
    "- Ciudad:\n",
    "\n",
    "        Bogotá → [1, 0, 0]\n",
    "\n",
    "        Medellín → [0, 1, 0]\n",
    "\n",
    "        Cali → [0, 0, 1]\n",
    "\n",
    "Esto crea una matriz binaria llamada \"matriz disyuntiva completa\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c08277",
   "metadata": {},
   "source": [
    "### Paso 2: Cálculo de perfiles y distancias\n",
    "\n",
    "Se calcula la proporción de veces que aparece cada categoría en cada fila (individuo).\n",
    "\n",
    "La **distancia entre dos individuos** se basa en la diferencia en sus perfiles. Se calcula así:\n",
    "\n",
    "$$\n",
    "d^2(i, i') = \\sum_{j} \\frac{1}{f_j} (x_{ij} - x_{i'j})^2\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- $f_j$: frecuencia de la categoría $j$.\n",
    "- $x_{ij}$: valor binario (0 o 1) del individuo $i$ en la categoría $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd979784",
   "metadata": {},
   "source": [
    "## Paso 3: Descomposición en valores singulares (SVD)\n",
    "\n",
    "Se aplica la misma idea que en el Análisis de Componentes Principales (ACP), pero sobre los **perfiles**.\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \\mathbf{U} \\mathbf{D} \\mathbf{V}^T\n",
    "$$\n",
    "\n",
    "- $\\mathbf{D}$: matriz diagonal que contiene las \"inertias\" o varianzas explicadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bbecfb",
   "metadata": {},
   "source": [
    "## Paso 4: Evaluación del ACM\n",
    "\n",
    "**Inercia**\n",
    "\n",
    "- Es el equivalente a la **varianza** en PCA.\n",
    "- Mide la **dispersión global** de los perfiles de individuos o categorías.\n",
    "- Se basa en la **distancia chi-cuadrado**.\n",
    "\n",
    "Fórmula:\n",
    "\n",
    "$$\n",
    "\\text{Inercia total} = \\frac{\\chi^2}{n}\n",
    "$$\n",
    "\n",
    "- $\\chi^2$: estadístico de chi-cuadrado global de la tabla.\n",
    "- $n$: número total de observaciones.\n",
    "\n",
    "> **Interpretación**: Mayor inercia implica relaciones más fuertes entre categorías.\n",
    "\n",
    "\n",
    "** 2. % de Inercia Explicada**\n",
    "\n",
    "- Mide **cuánta información** aporta cada eje factorial.\n",
    "- Ayuda a decidir **cuántos ejes conservar** para representar los datos.\n",
    "\n",
    "**Fórmula:**\n",
    "\n",
    "$$\n",
    "\\% \\text{Inercia explicada} = \\frac{\\lambda_k}{\\sum \\lambda} \\times 100\n",
    "$$\n",
    "\n",
    "- $\\lambda_k$: inercia del eje $k$ (autovalor).\n",
    "- $\\sum \\lambda$: inercia total.\n",
    "\n",
    "> Se visualiza en un gráfico de sedimentación (**scree plot**).\n",
    "\n",
    "\n",
    "**3. Coordenadas Principales**\n",
    "\n",
    "- Representan la **nueva posición** de individuos o categorías en los ejes.\n",
    "\n",
    "**Fórmulas** (con SVD de la matriz centrada):\n",
    "\n",
    "- Individuos:\n",
    "  $$\n",
    "  \\mathbf{F} = \\mathbf{U} \\cdot \\boldsymbol{\\Sigma}\n",
    "  $$\n",
    "- Categorías:\n",
    "  $$\n",
    "  \\mathbf{G} = \\mathbf{V} \\cdot \\boldsymbol{\\Sigma}\n",
    "  $$\n",
    "\n",
    "> Útiles para **visualizar asociaciones** y detectar agrupaciones en planos factoriales.\n",
    "\n",
    "**4. Contribuciones**\n",
    "\n",
    "- Indican **cuánto aporta** cada individuo o categoría a la construcción de un eje.\n",
    "\n",
    "**Fórmula:**\n",
    "\n",
    "$$\n",
    "\\text{CTR}_{ik} = \\frac{f_i \\cdot F_{ik}^2}{\\lambda_k}\n",
    "$$\n",
    "\n",
    "- $f_i$: masa (frecuencia relativa) del individuo $i$.\n",
    "- $F_{ik}$: coordenada del individuo en el eje $k$.\n",
    "- $\\lambda_k$: inercia del eje.\n",
    "\n",
    "> Valores altos indican **elementos representativos del eje**.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
